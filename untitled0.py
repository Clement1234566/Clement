# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j7tab1W7v6M6b0S8EFrRtS1TSGBYCzRm
"""

import pandas as pd
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, RobustScaler
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import pickle

"""Preprocessing data"""

df = pd.read_csv("Dataset_A_loan.csv")

df.info()

df.head()

"""PREPROCESSING

"""

print(" Missing Value:", df.isnull().sum())

#Handle missing value
df.fillna(df.median(numeric_only=True), inplace=True)
df.dropna(inplace=True)
print("\n After handle missing value:\n", df.isnull().sum())

#Split Data
xx = df[df.columns.drop(['loan_status'])]
y = df['loan_status']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Kolom numerik
print("Kolom Numerik:\n", df.select_dtypes(include=['number']).columns)

# Kolom kategorikal
print("\nKolom Kategorikal:\n", df.select_dtypes(include=['object', 'category']).columns)

# Konversi kategorikal menjadi numerik dengan LabelEncoder
categorical_cols = x_train.select_dtypes(include=['object', 'category']).columns
encoder = LabelEncoder()
for col in categorical_cols:
    x_train[col] = encoder.fit_transform(x_train[col])
    x_test[col] = encoder.transform(x_test[col])

print("\nData setelah encoding:")
print(df.head())

# Train the model
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(x_train, y_train)
rf_pred = rf_model.predict(x_test)
rf_f1 = f1_score(y_test, rf_pred)

xgb_model = XGBClassifier(eval_metric='logloss')
xgb_model.fit(x_train, y_train)
xgb_pred = xgb_model.predict(x_test)
xgb_f1 = f1_score(y_test, xgb_pred)

print("Random Forest Report:")
print(classification_report(y_test, rf_pred))
print("\nXGBoost Report:")
print(classification_report(y_test, xgb_pred))

# Simpan model terbaik
best_model = xgb_model if xgb_f1 > rf_f1 else rf_model
with open("best_model.pkl", "wb") as f:
    pickle.dump(best_model, f)

"""FORMAT OOP"""

class LoanModelTrainer:
    def __init__(self, data_path):
        self.data_path = data_path
        self.df = None
        self.X_train = self.X_test = self.y_train = self.y_test = None
        self.scaler = StandardScaler()
        self.encoder = LabelEncoder()
        self.best_model = None

    def load_and_preprocess(self):
        self.df = pd.read_csv(self.data_path)
        self.df.fillna(self.df.mean(numeric_only=True), inplace=True)
        self.df.fillna(method='ffill', inplace=True)

        categorical_cols = self.df.select_dtypes(include=['object', 'category']).columns
        for col in categorical_cols:
            self.df[col] = self.encoder.fit_transform(self.df[col])

        X = self.df.drop('loan_status', axis=1)
        y = self.df['loan_status']
        X_scaled = self.scaler.fit_transform(X)

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )

    def train_models(self):
        rf_model = RandomForestClassifier(random_state=42)
        rf_model.fit(self.X_train, self.y_train)
        rf_pred = rf_model.predict(self.X_test)
        rf_f1 = f1_score(self.y_test, rf_pred)

        xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
        xgb_model.fit(self.X_train, self.y_train)
        xgb_pred = xgb_model.predict(self.X_test)
        xgb_f1 = f1_score(self.y_test, xgb_pred)

        print("Random Forest Report:")
        print(classification_report(self.y_test, rf_pred))
        print("\nXGBoost Report:")
        print(classification_report(self.y_test, xgb_pred))

        self.best_model = xgb_model if xgb_f1 > rf_f1 else rf_model

class LoanModelTrainer:
    def __init__(self, data_path):
        self.data_path = data_path
        self.df = None
        self.X_train = self.X_test = self.y_train = self.y_test = None
        self.scaler = StandardScaler()
        self.encoder = LabelEncoder()
        self.best_model = None

    def load_and_preprocess(self):
        self.df = pd.read_csv(self.data_path)
        self.df.fillna(self.df.mean(numeric_only=True), inplace=True)
        self.df.fillna(method='ffill', inplace=True)

        categorical_cols = self.df.select_dtypes(include=['object', 'category']).columns
        for col in categorical_cols:
            self.df[col] = self.encoder.fit_transform(self.df[col])

        X = self.df.drop('loan_status', axis=1)
        y = self.df['loan_status']
        X_scaled = self.scaler.fit_transform(X)

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            X_scaled, y, test_size=0.2, random_state=42
        )

    def train_models(self):
        rf_model = RandomForestClassifier(random_state=42)
        rf_model.fit(self.X_train, self.y_train)
        rf_pred = rf_model.predict(self.X_test)
        rf_f1 = f1_score(self.y_test, rf_pred)

        xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
        xgb_model.fit(self.X_train, self.y_train)
        xgb_pred = xgb_model.predict(self.X_test)
        xgb_f1 = f1_score(self.y_test, xgb_pred)

        print("Random Forest Report:")
        print(classification_report(self.y_test, rf_pred))
        print("\nXGBoost Report:")
        print(classification_report(self.y_test, xgb_pred))

        self.best_model = xgb_model if xgb_f1 > rf_f1 else rf_model

    def save_model(self, filename="best_model.pkl"):
        with open(filename, "wb") as f:
            pickle.dump(self.best_model, f)

def load_model(filename="best_model.pkl"):
    with open(filename, "rb") as f:
        model = pickle.load(f)
    return model

def predict_loan_status(model, scaler, input_data):
    input_df = pd.DataFrame([input_data])
    input_scaled = scaler.transform(input_df)
    prediction = model.predict(input_scaled)
    print("Prediksi untuk input:", input_data)

    return prediction[0]

